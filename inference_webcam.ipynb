{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference 코드 - 웹캠적용\n",
    "\n",
    "모델학습을 위해서 이미지데이터 + 감정텍스트 데이터 2가지 종류의 데이터를 input으로 넣어주었기 때문에 face로도 충분히 멀티모달을 활용\n",
    "\n",
    "여기서는 웹캠을 활용해서 실시간으로 얼굴 감정 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 확인\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset 만들기\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Detect Face\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "# Moel\n",
    "import torch\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import batch_normalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 함수\n",
    "# inference를 할 때는 저장된 모델에 학습데이터와 동일한 형태의 input을 넣어주어야 하기 때문에\n",
    "# 동일한 전처리 과정을 거쳐 동일한 형태의 input shape이 나오도록 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = 48\n",
    "shape_y = 48\n",
    "\n",
    "# 전체 이미지에서 얼굴을 찾아내는 함수\n",
    "def detect_face(frame):\n",
    "    # cascade pre-trained 모델 불러오기\n",
    "    face_cascasde = cv2.CascadeClassifier(cv2.date.haarcascades + 'harrrcascade_frontalface_default.xml')\n",
    "    \n",
    "    # RGB를 gray scale로 바꾸기\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # cascade 멀티스케일 분류\n",
    "    detected_face = face_cascasde.detectMultiScale(gray,\n",
    "                                                 scaleFactor=1.1,\n",
    "                                                 minNeighbors=6,\n",
    "                                                 minSize=(shape_X, shape_y),\n",
    "                                                 flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    coord = []\n",
    "    for x, y, w, h in detected_face:\n",
    "        if w > 100:\n",
    "            sub_img = frame[y:y+h, x:x+w]\n",
    "            coord.append([x,y,w,h])\n",
    "    \n",
    "    return gray, detected_face, coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 이미지에서 찾아낸 얼굴을 추출하는 함수\n",
    "def extract_face_features(gray, detected_faces, coord, offset_coefficients=(0.075, 0.05)):\n",
    "    new_face=[]\n",
    "    for det in detected_faces:\n",
    "        \n",
    "        # 얼굴로 감지된 영역\n",
    "        x,y,w,h = det\n",
    "        \n",
    "        # 이미지 경계값 받기\n",
    "        horizontal_offset = np.int(np.floor(offset_coefficients[0] * w))\n",
    "        verical_offset = np.int(np.floor(offset_coefficients[1] * h))\n",
    "        \n",
    "        # gray scale에서 해당 위치 가져오기\n",
    "        extracted_face = gray[y+verical_offset:y+h, x+horizontal_offset:x-horizontal_offset+w]\n",
    "        \n",
    "        # 얼굴 이미지만 확대\n",
    "        new_extracted_face = zoom(extracted_face, (shape_x/extracted_face.shape[0], shape_y/extracted_face[1]))\n",
    "        new_extracted_face = new_extracted_face.astype(np.float32)\n",
    "        new_extracted_face /= float(new_extracted_face.max()) # scaled\n",
    "        new_face.append(new_extracted_face)\n",
    "        \n",
    "    return new_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "model = keras.models.load_model('./face_emotions.h5')\n",
    "\n",
    "# 인덱스번호로 웹캠연결 대부분 시스템적으로 0번부터 부여됨\n",
    "video_capture = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프레임 단위로 영상 캡쳐\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    # ret: 비디오를 성공적으로 읽어왔는지 확인 True/False\n",
    "    # frame: 각 픽셀의 색상을 포함한 프레임 정보 Numpy\n",
    "    \n",
    "    face_index = 0\n",
    "    gray, detected_faces, coord = detect_face(frame)\n",
    "    \n",
    "    try:\n",
    "        face_zoom = extract_face_features(gray, detected_faces, coord)\n",
    "        face_zoom = np.reshape(face_zoom[0].flatten(), (1,48,48,1))\n",
    "        x, y, w, h = coord[face_index]\n",
    "        \n",
    "        # 머리 둘레에 직사각형 그리기: (0, 255, 0)을 통해 녹색, 선두께 2\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0),2)\n",
    "        \n",
    "        # 감정 예측\n",
    "        pred = model.predict(face_zoom)\n",
    "        pred_result = np.argmax(pred)\n",
    "        \n",
    "        # 각 라벨별 예측 정도 표시\n",
    "        cv2.putText(frame,                                  # 텍스트를 표시할 프레임\n",
    "                    \"Angry: \" + str(round(pred[0][0], 3)),  # 텍스트 표시 \"감정: 예측 probability\" 소수점 3번째 자리까지\n",
    "                    (10,50),                                # 텍스트 위치\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,               # 폰트 종류\n",
    "                    1,                                      # 폰트 사이즈 \n",
    "                    (0,0,255),                              # 폰트 색상\n",
    "                    2                                       # 폰트 두께\n",
    "                    )\n",
    "        cv2.putText(frame, \"Disgust: \" + str(round(pred[0][1], 3)), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Fear: \" + str(round(pred[0][2], 3)), (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Happy: \" + str(round(pred[0][3], 3)), (10, 170), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Sad: \" + str(round(pred[0][4], 3)), (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Surprise: \" + str(round(pred[0][5], 3)), (10, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Neutral: \" + str(round(pred[0][6], 3)), (10, 290), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # 예측값이 높은 라벨 하나만 프레임 옆에 표시\n",
    "        if pred_result == 0:\n",
    "            cv2.putText(frame, \"Angry \" + str(round(pred[0][0], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        elif pred_result == 1:\n",
    "            cv2.putText(frame, \"Disgust \" + str(round(pred[0][1], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        elif pred_result == 2:\n",
    "            cv2.putText(frame, \"Fear \" + str(round(pred[0][2], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        elif pred_result == 3:\n",
    "            cv2.putText(frame, \"Happy \" + str(round(pred[0][3], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        elif pred_result == 4:\n",
    "            cv2.putText(frame, \"Sad \" + str(round(pred[0][4], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        elif pred_result == 5:\n",
    "            cv2.putText(frame, \"Surprise \" + str(round(pred[0][5], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        else:\n",
    "            cv2.putText(frame, \"Neutral \" + str(round(pred[0][6], 2)), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 5)\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # 결과 표시\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # 사용자가 q 키를 누르면 종료\n",
    "    if cv2.waitkey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 웹캠 해제\n",
    "video_capture.release()\n",
    "\n",
    "# 창 닫기 (창이 제대로 종료되지 않을 경우 쥬피터 close)\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
